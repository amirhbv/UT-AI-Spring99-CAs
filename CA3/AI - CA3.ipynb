{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI - Computer Assignment 3\n",
    "\n",
    "## Text Processing and Naïve Bayes\n",
    "\n",
    "In this assignment we are going to classify news using Bayes theorem. in Bayes theorem we have\n",
    "\n",
    "$$ P(C_i | X) = \\frac{P(C_i) * P(X | C_i)}{P(X)} $$\n",
    "            \n",
    "We try tu classify texts using above formula. For using Bayes theorem we need 4 values:\n",
    "\n",
    "- Posterior Probability: Which is the probability of a news piece being in category $C_i$ if it include the words $X$.\n",
    "- Likelihood: Which is the probability of the word $X_i$ being in a news peace of category $C_i$.\n",
    "- Class Prior Probability: Which is The probability of a news piece being in category $C_i$.\n",
    "- Posterior Probability: Which is the probability of a word being $X_i$, which is constant and can be removed.\n",
    "\n",
    "So we can calculate Posterior Probability using following formula:\n",
    "\n",
    "$$ P(C_i | X) = P(C_i) * P(X_1 | C_i) * \\dots * * P(X_n | C_i) $$\n",
    "\n",
    "In the training phase we calculate the likelihood for each word in each category, to use in evalute and test phases. We also calculate Class Prior Probability which is the number of news pieces in the $C_i$ category divided by the total number of news pieces.\n",
    "\n",
    "Following block is implementation of Classifier class with utility functions and helper class for category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "from random import random\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    def get_wordnet_pos(nltk_tag):\n",
    "        return {\n",
    "            \"J\": wordnet.ADJ,\n",
    "            \"N\": wordnet.NOUN,\n",
    "            \"V\": wordnet.VERB,\n",
    "            \"R\": wordnet.ADV,\n",
    "        }.get(nltk_tag[0].upper(), None)\n",
    "\n",
    "    result = []\n",
    "    for sentence in nltk.sent_tokenize(text):\n",
    "        tagged_sentence = [\n",
    "            (word, get_wordnet_pos(tag))\n",
    "            for (word, tag) in nltk.pos_tag(nltk.regexp_tokenize(sentence.lower(), r'\\w+'))\n",
    "            if len(word) > 1 and word not in stop_words\n",
    "        ]\n",
    "\n",
    "        for word, tag in tagged_sentence:\n",
    "            if tag:\n",
    "                word = lemmatizer.lemmatize(word, tag)\n",
    "            else:\n",
    "                word = lemmatizer.lemmatize(word)\n",
    "\n",
    "            result.append(word)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "class Classifier:\n",
    "\n",
    "    class Category:\n",
    "\n",
    "        def __init__(self, category_title, category_total_rows, data_total_rows):\n",
    "            self.category_title = category_title\n",
    "            self.category_probability = category_total_rows / data_total_rows\n",
    "\n",
    "            self.words = Counter()\n",
    "            self.word_count = 0\n",
    "\n",
    "        def add_text(self, text):\n",
    "            for word in clean_text(text):\n",
    "                self.words[word] += 1\n",
    "                self.word_count += 1\n",
    "\n",
    "        def calculate_probability(self, text):\n",
    "            p = math.log10(self.category_probability)\n",
    "            for word in clean_text(text):\n",
    "                p += math.log10((self.words[word] or 0.1) / self.word_count)\n",
    "\n",
    "            return p\n",
    "\n",
    "    def __init__(self, data_file_name, classification_cols, category_col, oversample=False):\n",
    "        self._category_col = category_col\n",
    "        self._classification_cols = classification_cols\n",
    "\n",
    "        df = pd.read_csv(data_file_name,\n",
    "                         usecols=[*classification_cols, category_col])\n",
    "\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "        self.total_rows, _ = df.shape\n",
    "        category_titles = df[category_col].unique()\n",
    "\n",
    "        df = df.groupby(category_col)\n",
    "        max_category_data_rows = max([\n",
    "            categpry_data_rows\n",
    "            for categpry_data_rows, _ in [\n",
    "                category.shape for _, category in df\n",
    "            ]\n",
    "        ])\n",
    "\n",
    "        self.categories = {}\n",
    "        self.test_data = {}\n",
    "        for category_title in category_titles:\n",
    "            category_df = df.get_group(category_title)\n",
    "            category_total_rows, _ = category_df.shape\n",
    "\n",
    "            if oversample:\n",
    "                category_df = category_df.append(\n",
    "                    category_df.sample(\n",
    "                        n=max_category_data_rows - category_total_rows,\n",
    "                        replace=True,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            category_total_rows, _ = category_df.shape\n",
    "            category = Classifier.Category(\n",
    "                category_title, category_total_rows, self.total_rows)\n",
    "\n",
    "            test_data = []\n",
    "            for _, row in category_df.iterrows():\n",
    "                if random() < 0.8:\n",
    "                    for col in classification_cols:\n",
    "                        category.add_text(row[col])\n",
    "                else:\n",
    "                    test_data.append(row)\n",
    "\n",
    "            self.test_data[category_title] = pd.DataFrame(\n",
    "                columns=category_df.columns,\n",
    "                data=test_data,\n",
    "            )\n",
    "\n",
    "            self.categories[category_title] = category\n",
    "\n",
    "    def _find_category(self, text, include_categories=None):\n",
    "        _, result_category = max([\n",
    "            (category.calculate_probability(text), category.category_title)\n",
    "            for category in self.categories.values()\n",
    "            if not include_categories or category.category_title in include_categories\n",
    "        ])\n",
    "\n",
    "        return result_category\n",
    "\n",
    "    def evaluate(self, classification_col, categories=None):\n",
    "        valid_categories = list(self.categories.keys())\n",
    "        if not categories:\n",
    "            categories = valid_categories\n",
    "        else:\n",
    "            categories = [\n",
    "                category for category in categories if category in valid_categories]\n",
    "\n",
    "        actual_categories, predicted_categories = zip(*[\n",
    "            (category, self._find_category(\n",
    "                row[classification_col], categories))\n",
    "            for category in categories\n",
    "            for _, row in self.test_data[category].iterrows()\n",
    "        ])\n",
    "\n",
    "        category_indices = {\n",
    "            category: index for (index, category) in enumerate(categories)\n",
    "        }\n",
    "\n",
    "        confustion_matrix = [[0 for _ in categories] for _ in categories]\n",
    "        for actual_category, predicted_category in zip(actual_categories, predicted_categories):\n",
    "            confustion_matrix[\n",
    "                category_indices[actual_category]\n",
    "            ][\n",
    "                category_indices[predicted_category]\n",
    "            ] += 1\n",
    "\n",
    "        confustion_matrix_table = PrettyTable(\n",
    "            field_names=[\n",
    "                'Confusion Matrix',\n",
    "                *categories\n",
    "            ],\n",
    "        )\n",
    "        for i, row in enumerate(confustion_matrix):\n",
    "            confustion_matrix_table.add_row([\n",
    "                categories[i],\n",
    "                *row,\n",
    "            ])\n",
    "\n",
    "        print(confustion_matrix_table)\n",
    "\n",
    "        metrics_table = PrettyTable(\n",
    "            field_names=[\n",
    "                '',\n",
    "                'Accuracy',\n",
    "                'Precision',\n",
    "                'Recall',\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        all_true_positive_cases = sum(\n",
    "            confustion_matrix[i][i] for i in range(len(confustion_matrix)))\n",
    "        all_cases = len(actual_categories)\n",
    "        accuracy = all_true_positive_cases / all_cases\n",
    "\n",
    "        for i, category in enumerate(categories):\n",
    "            true_positive_cases = confustion_matrix[i][i]\n",
    "            actual_positive_cases = sum(\n",
    "                confustion_matrix[i][j] for j in range(len(confustion_matrix)))\n",
    "            predicted_positive_cases = sum(\n",
    "                confustion_matrix[j][i] for j in range(len(confustion_matrix)))\n",
    "\n",
    "            precision = true_positive_cases / predicted_positive_cases\n",
    "            recall = true_positive_cases / actual_positive_cases\n",
    "\n",
    "            metrics_table.add_row([\n",
    "                category,\n",
    "                accuracy,\n",
    "                precision,\n",
    "                recall,\n",
    "            ])\n",
    "\n",
    "        print(metrics_table)\n",
    "\n",
    "        return confustion_matrix\n",
    "\n",
    "    def classify(self, test_file_name, classification_col):\n",
    "        df = pd.read_csv(test_file_name, usecols=[\n",
    "                         'index', classification_col]).dropna()\n",
    "\n",
    "        df[self._category_col] = df[classification_col].apply(\n",
    "            self._find_category)\n",
    "\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data\n",
    "The `clean_text` method is used to clean the given data. It uses `NLTK` tokenizers and `WordNetLemmatizer`. First it gets sentences from the text and then for each sentence, it finds the part of speech for each word which is not a stop word. Then using the `WordNetLemmatizer` from `NLTK` it lemmatizes the remaining words. The resulting words are base or dictionary form of each word, which is known as the lemma. Before processing any peace of text this functions is called on the text.\n",
    "\n",
    "### Classifer\n",
    "The `Classifier` gets the dataset and the classification columns and the category columns of the dataset as arguments to constructor. The classifier oversamples the data if it has a ```oversample=True``` argument which will be explained later.\n",
    "\n",
    "#### Training\n",
    "Training phase is done in the constructor, after opening the dataset as `pandas` data frame, total rows and category titles are extracted from dataset. Then dataset is grouped by the category column, for each category 80% of data is used for training and the rest is stored to evaluate the model. Number of words for each category are stored in instances of `Category` class.\n",
    "\n",
    "#### Evaluate\n",
    "There is a `evaluate` method which gets the classification columns and categories to include, if none is provided all of the categories all used to evaluate the model. It calculates the probability of each peace of news being in every category and chosse the category with highest probability as news category. Then confusion matrix and some metrics are printed.\n",
    "\n",
    ">##### Confusion Matrix\n",
    "The confusion matrix, is a table with two dimensions (“Actual” and “Predicted”), and sets of “categories” in both dimensions. Our \"Actual\" classifications are rows and \"Predicted\" ones are columns. Then each cell is number of news peaces as the actual category and predicted one. The Confusion matrix in itself is not a performance measure as such, but almost all of the performance metrics are based on Confusion Matrix and the numbers inside it:\n",
    "\n",
    ">>###### Accuracy\n",
    "Accuracy in is the number of correct predictions made by the model over all kinds predictions made.\n",
    "\n",
    ">>###### Precision\n",
    "Precision is the number of correct predictions over predicted cases in each category.\n",
    "\n",
    ">>###### Recall\n",
    "Recall is the number of correct predictions over actual cases in each category.\n",
    "\n",
    "#### Test\n",
    "The `test` method gets a test dataset and find categories for every news peace in that. A pandas data frame is returned.\n",
    "\n",
    "Now let's test the classifiers,\n",
    "First we train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time (train): 32.95787072181702\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "start = time()\n",
    "classifier = Classifier(\n",
    "    data_file_name='./data.csv',\n",
    "    classification_cols=['short_description', 'headline'],\n",
    "    category_col='category',\n",
    "    oversample=True,\n",
    ")\n",
    "print(\"Elapsed Time (train):\", time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate the model using travel and business categories as wanted in the phase1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+----------+\n",
      "| Confusion Matrix | TRAVEL | BUSINESS |\n",
      "+------------------+--------+----------+\n",
      "|      TRAVEL      |  1677  |   136    |\n",
      "|     BUSINESS     |  116   |   1627   |\n",
      "+------------------+--------+----------+\n",
      "+----------+--------------------+--------------------+--------------------+\n",
      "|          |      Accuracy      |     Precision      |       Recall       |\n",
      "+----------+--------------------+--------------------+--------------------+\n",
      "|  TRAVEL  | 0.9291338582677166 | 0.9353039598438372 | 0.9249862107004965 |\n",
      "| BUSINESS | 0.9291338582677166 | 0.9228587634713556 | 0.9334480780263913 |\n",
      "+----------+--------------------+--------------------+--------------------+\n",
      "Elapsed Time (evaluate phase1): 7.449356317520142\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "confustion_matrix = classifier.evaluate(\n",
    "    classification_col='short_description',\n",
    "    categories=[\"TRAVEL\", \"BUSINESS\"],\n",
    ")\n",
    "print(\"Elapsed Time (evaluate phase1):\", time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate the model using all categories as wanted in phase2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+----------------+----------+\n",
      "| Confusion Matrix | TRAVEL | STYLE & BEAUTY | BUSINESS |\n",
      "+------------------+--------+----------------+----------+\n",
      "|      TRAVEL      |  1613  |       79       |   121    |\n",
      "|  STYLE & BEAUTY  |  191   |      1474      |    97    |\n",
      "|     BUSINESS     |   98   |       50       |   1595   |\n",
      "+------------------+--------+----------------+----------+\n",
      "+----------------+--------------------+--------------------+--------------------+\n",
      "|                |      Accuracy      |     Precision      |       Recall       |\n",
      "+----------------+--------------------+--------------------+--------------------+\n",
      "|     TRAVEL     | 0.8804061677322301 | 0.8480546792849631 | 0.8896856039713182 |\n",
      "| STYLE & BEAUTY | 0.8804061677322301 | 0.9195258889582034 | 0.8365493757094211 |\n",
      "|    BUSINESS    | 0.8804061677322301 | 0.8797573083287369 | 0.9150889271371199 |\n",
      "+----------------+--------------------+--------------------+--------------------+\n",
      "Elapsed Time (evaluate phase2): 16.109183073043823\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "confustion_matrix = classifier.evaluate(\n",
    "    classification_col='short_description',\n",
    ")\n",
    "print(\"Elapsed Time (evaluate phase2):\", time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And test the model, the result is saved in \"output.csv\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time (classify): 6.985297441482544\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "res = classifier.classify(\n",
    "    test_file_name='./test.csv',\n",
    "    classification_col='short_description',\n",
    ")\n",
    "print(\"Elapsed Time (classify):\", time() - start)\n",
    "res[['index', 'category']].to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampling\n",
    "As we can see the data provided for buisiness category is about half in count compared to other categories, which causes the Class prior probability of this category less than others. We interpolate the data of this category to make the length of data in each category the same. This is called oversampling.\n",
    "\n",
    "#### Lemmatization vs Stemming\n",
    "Lemmatization is preferred over Stemming because lemmatization does morphological analysis of the words which seems to be a better choice. But here it gives us only 1 percent of better results.\n",
    "\n",
    "#### Word only in one category\n",
    "We used logarithm to make the calculation simpler (as the multiplications becomes summation), so if a word is not present in a category we assign a very low likelihood to that word the prevent log(0) problem. By this condition if a word is present only in category, that peace is chosen to have that category.\n",
    "\n",
    "#### Considering precision as the only metric\n",
    "Precision is about being precise, which is number of true positive cases over all predicted positive cases. If we have that detects cancer, in a dataset of 100 patients with 5 person diagnosed with cancer, if we only detect one positive case which is true, we have a precision of 100% but there were 4 unpredicted peaple, i.e. we have a recall of 20% which not good.\n",
    "\n",
    "#### TF-IDF\n",
    "TF (Term Frequency) is frequency of a word in a document over number of all word in the documents, same as what we used here except that we removed the stop words.\n",
    "IDF (Inverse Document Frequency) is how important a word is in a category, which is number of documents the words appear in over number of all documents. It tries to weigh down words like stop words that appear a lot in documents and weigh up rare words of each document in each category.\n",
    "This measure can be used is likelihood."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UT-AI",
   "language": "python",
   "name": "ut-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
